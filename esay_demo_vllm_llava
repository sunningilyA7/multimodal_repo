{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":803.741372,"end_time":"2024-10-27T06:12:38.713054","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-27T05:59:14.971682","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"3ae3375ceefd42f9aeede66494e08172":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_712906b89a034aa981c78ec917695c16","IPY_MODEL_6e02449d72574cb59a7408135ddf0606","IPY_MODEL_aabe4ff8b2734c9c86a33deb7a3d0a52"],"layout":"IPY_MODEL_d865f8a6c163451da7719a6d6e720f96"}},"63273838b2cf407a9d8a4b3d3c0a6096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64efbe72d2c24a98b72db29e311e7206":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e02449d72574cb59a7408135ddf0606":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_805d7686fa99450fa5f28d53a2e50938","max":11,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c76df798b0e0495abc6131f26e897eca","value":11}},"712906b89a034aa981c78ec917695c16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af9c9877f8c347788ca34cdd8170fc94","placeholder":"​","style":"IPY_MODEL_c9c855af5c4941d6bed6542ce711a012","value":""}},"805d7686fa99450fa5f28d53a2e50938":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aabe4ff8b2734c9c86a33deb7a3d0a52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63273838b2cf407a9d8a4b3d3c0a6096","placeholder":"​","style":"IPY_MODEL_64efbe72d2c24a98b72db29e311e7206","value":"Loading safetensors checkpoint shards: 100% Completed | 11/11 [04:33&lt;00:00, 26.87s/it]\n"}},"af9c9877f8c347788ca34cdd8170fc94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76df798b0e0495abc6131f26e897eca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9c855af5c4941d6bed6542ce711a012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d865f8a6c163451da7719a6d6e720f96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import set_seed\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T06:55:39.125045Z","iopub.execute_input":"2025-01-16T06:55:39.125269Z","iopub.status.idle":"2025-01-16T06:56:06.187134Z","shell.execute_reply.started":"2025-01-16T06:55:39.125243Z","shell.execute_reply":"2025-01-16T06:56:06.186398Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport warnings\n\nimport pandas as pd\nimport polars as pl\n\nimport torch\nimport kaggle_evaluation.aimo_2_inference_server\n\npd.set_option('display.max_colwidth', None)\ncutoff_time = time.time() + (4 * 60 + 45) * 60","metadata":{"papermill":{"duration":15.076705,"end_time":"2024-10-27T05:59:33.712437","exception":false,"start_time":"2024-10-27T05:59:18.635732","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-16T06:42:35.131506Z","iopub.execute_input":"2025-01-16T06:42:35.132207Z","iopub.status.idle":"2025-01-16T06:42:35.940045Z","shell.execute_reply.started":"2025-01-16T06:42:35.132176Z","shell.execute_reply":"2025-01-16T06:42:35.939332Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install  git+https://github.com/huggingface/peft.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T06:58:57.647585Z","iopub.execute_input":"2025-01-16T06:58:57.647966Z","iopub.status.idle":"2025-01-16T06:59:19.147498Z","shell.execute_reply.started":"2025-01-16T06:58:57.647936Z","shell.execute_reply":"2025-01-16T06:59:19.146392Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/peft.git\n  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-a051yksk\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-a051yksk\n  Resolved https://github.com/huggingface/peft.git to commit 63ae263644b9a2527dccd1970bd934e317a6173e\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (24.1)\nRequirement already satisfied: psutil in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (6.1.0)\nRequirement already satisfied: pyyaml in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (2.4.0)\nRequirement already satisfied: transformers in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (4.46.1)\nRequirement already satisfied: tqdm in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (4.66.6)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.34.2)\nRequirement already satisfied: safetensors in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (0.4.5)\nRequirement already satisfied: huggingface_hub>=0.25.0 in /kaggle/usr/lib/vllm-installation-fix (from peft==0.14.1.dev0) (0.26.2)\nRequirement already satisfied: filelock in /kaggle/usr/lib/vllm-installation-fix (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /kaggle/usr/lib/vllm-installation-fix (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.9.0)\nRequirement already satisfied: requests in /kaggle/usr/lib/vllm-installation-fix (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /kaggle/usr/lib/vllm-installation-fix (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (4.12.2)\nRequirement already satisfied: sympy in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (1.13.3)\nRequirement already satisfied: networkx in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (3.4.2)\nRequirement already satisfied: jinja2 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.13.0->peft==0.14.1.dev0) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /kaggle/usr/lib/vllm-installation-fix (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.14.1.dev0) (12.6.77)\nRequirement already satisfied: regex!=2019.12.17 in /kaggle/usr/lib/vllm-installation-fix (from transformers->peft==0.14.1.dev0) (2024.9.11)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /kaggle/usr/lib/vllm-installation-fix (from transformers->peft==0.14.1.dev0) (0.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /kaggle/usr/lib/vllm-installation-fix (from jinja2->torch>=1.13.0->peft==0.14.1.dev0) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /kaggle/usr/lib/vllm-installation-fix (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /kaggle/usr/lib/vllm-installation-fix (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /kaggle/usr/lib/vllm-installation-fix (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /kaggle/usr/lib/vllm-installation-fix (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /kaggle/usr/lib/vllm-installation-fix (from sympy->torch>=1.13.0->peft==0.14.1.dev0) (1.3.0)\nBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peft: filename=peft-0.14.1.dev0-py3-none-any.whl size=389034 sha256=bd55e212522afa25287b595ac5c511d485551a7c6c035fa8c475fd27f0d45fe8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-16jks_67/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\nSuccessfully built peft\nInstalling collected packages: peft\nSuccessfully installed peft-0.14.1.dev0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install  git+https://github.com/huggingface/trl.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T06:59:59.195497Z","iopub.execute_input":"2025-01-16T06:59:59.196288Z","iopub.status.idle":"2025-01-16T07:00:18.948371Z","shell.execute_reply.started":"2025-01-16T06:59:59.196252Z","shell.execute_reply":"2025-01-16T07:00:18.947506Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/huggingface/trl.git\n  Cloning https://github.com/huggingface/trl.git to /tmp/pip-req-build-c7t8q1mo\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-c7t8q1mo\n  Resolved https://github.com/huggingface/trl.git to commit 57d9a97394b4dd3aa5cd13dffdc99770b6326af2\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.14.0.dev0) (0.34.2)\nRequirement already satisfied: datasets>=2.21.0 in /kaggle/usr/lib/vllm-installation-fix (from trl==0.14.0.dev0) (3.1.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl==0.14.0.dev0) (13.7.1)\nRequirement already satisfied: transformers>=4.46.0 in /kaggle/usr/lib/vllm-installation-fix (from trl==0.14.0.dev0) (4.46.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (24.1)\nRequirement already satisfied: psutil in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (6.1.0)\nRequirement already satisfied: pyyaml in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (0.26.2)\nRequirement already satisfied: safetensors>=0.4.3 in /kaggle/usr/lib/vllm-installation-fix (from accelerate>=0.34.0->trl==0.14.0.dev0) (0.4.5)\nRequirement already satisfied: filelock in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (18.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (0.3.8)\nRequirement already satisfied: pandas in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (4.66.6)\nRequirement already satisfied: xxhash in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /kaggle/usr/lib/vllm-installation-fix (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.14.0.dev0) (2024.9.0)\nRequirement already satisfied: aiohttp in /kaggle/usr/lib/vllm-installation-fix (from datasets>=2.21.0->trl==0.14.0.dev0) (3.10.10)\nRequirement already satisfied: regex!=2019.12.17 in /kaggle/usr/lib/vllm-installation-fix (from transformers>=4.46.0->trl==0.14.0.dev0) (2024.9.11)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /kaggle/usr/lib/vllm-installation-fix (from transformers>=4.46.0->trl==0.14.0.dev0) (0.20.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.14.0.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.14.0.dev0) (2.18.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (2.4.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.17.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /kaggle/usr/lib/vllm-installation-fix (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /kaggle/usr/lib/vllm-installation-fix (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.14.0.dev0) (4.12.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.14.0.dev0) (0.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /kaggle/usr/lib/vllm-installation-fix (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /kaggle/usr/lib/vllm-installation-fix (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /kaggle/usr/lib/vllm-installation-fix (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /kaggle/usr/lib/vllm-installation-fix (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (2024.8.30)\nRequirement already satisfied: sympy in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (1.13.3)\nRequirement already satisfied: networkx in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.4.2)\nRequirement already satisfied: jinja2 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /kaggle/usr/lib/vllm-installation-fix (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /kaggle/usr/lib/vllm-installation-fix (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (12.6.77)\nRequirement already satisfied: python-dateutil>=2.8.2 in /kaggle/usr/lib/vllm-installation-fix (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /kaggle/usr/lib/vllm-installation-fix (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /kaggle/usr/lib/vllm-installation-fix (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2024.2)\nRequirement already satisfied: six>=1.5 in /kaggle/usr/lib/vllm-installation-fix (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.14.0.dev0) (1.16.0)\nRequirement already satisfied: propcache>=0.2.0 in /kaggle/usr/lib/vllm-installation-fix (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (0.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /kaggle/usr/lib/vllm-installation-fix (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /kaggle/usr/lib/vllm-installation-fix (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (1.3.0)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.14.0.dev0-py3-none-any.whl size=294960 sha256=cefbad818d1245540103389ffcda90112220318e962f5cbd97c6bcc3d302ea67\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rnthdmn6/wheels/22/0e/42/319b77b2648bb6140ef2b08b0478ede9ca3cc7879fcd022d36\nSuccessfully built trl\nInstalling collected packages: trl\nSuccessfully installed trl-0.14.0.dev0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:00:21.478843Z","iopub.execute_input":"2025-01-16T07:00:21.479548Z","iopub.status.idle":"2025-01-16T07:00:25.971625Z","shell.execute_reply.started":"2025-01-16T07:00:21.479508Z","shell.execute_reply":"2025-01-16T07:00:25.970950Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"from vllm import LLM, SamplingParams\n\n# warnings.simplefilter('ignore')\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# def clean_memory(deep=False):\n#     gc.collect()\n#     if deep:\n#         ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n#     torch.cuda.empty_cache()\n\n# llm_model_pth = '/kaggle/input/m/shelterw/qwen2.5/transformers/qwq-32b-preview-awq/1'\n\n# llm = LLM(\n#     llm_model_pth,\n#     #dtype=\"half\",                -> Changed this\n#     #max_num_seqs=128,            -> Changed this\n#     max_model_len=32768,#4096*10,         \n#     trust_remote_code=True,     \n#     tensor_parallel_size=4,      \n#     gpu_memory_utilization=0.96, \n# )","metadata":{"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:00:54.603815Z","iopub.execute_input":"2025-01-16T07:00:54.604461Z","iopub.status.idle":"2025-01-16T07:00:54.608318Z","shell.execute_reply.started":"2025-01-16T07:00:54.604426Z","shell.execute_reply":"2025-01-16T07:00:54.607684Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"llm = LLM(model=\"llava-hf/llava-1.5-7b-hf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:00:57.066801Z","iopub.execute_input":"2025-01-16T07:00:57.067569Z","iopub.status.idle":"2025-01-16T07:04:23.550631Z","shell.execute_reply.started":"2025-01-16T07:00:57.067534Z","shell.execute_reply":"2025-01-16T07:04:23.549943Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7233bd5375468b9eae7bbc6dff26fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c25b59f323324a76ab96b559ebaac89e"}},"metadata":{}},{"name":"stdout","text":"INFO 01-16 07:01:22 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='llava-hf/llava-1.5-7b-hf', speculative_config=None, tokenizer='llava-hf/llava-1.5-7b-hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=llava-hf/llava-1.5-7b-hf, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9cc7c88516b419784d0b61722ac7b5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0821a776fc94fdaa2df80fccfad4c27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd026fff7ada4db2afe5d2030265919b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d71f41cf504555a195c9750512b509"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99d1dcbd1f44166bc81e260bb3dc253"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cec68020307418a8992512437e4ad2c"}},"metadata":{}},{"name":"stdout","text":"INFO 01-16 07:01:24 model_runner.py:1056] Starting to load model llava-hf/llava-1.5-7b-hf...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/usr/lib/vllm-installation-fix/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n/kaggle/usr/lib/vllm-installation-fix/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n","output_type":"stream"},{"name":"stdout","text":"INFO 01-16 07:01:39 weight_utils.py:243] Using model weights format ['*.safetensors']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e709715112824862ae3e0a487fbdd5a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6808dc0fc8e34544a820cbb52bf47759"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf645696ada04bc3938e2c8611246be1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b530232ec22b4c8f96a06dd7452676c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e95119cd9754efb81a4cdd4292218e6"}},"metadata":{}},{"name":"stdout","text":"INFO 01-16 07:03:44 model_runner.py:1067] Loading model weights took 13.1342 GB\nINFO 01-16 07:03:49 gpu_executor.py:122] # GPU blocks: 788, # CPU blocks: 512\nINFO 01-16 07:03:49 gpu_executor.py:126] Maximum concurrency for 4096 tokens per request: 3.08x\nINFO 01-16 07:03:51 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\nINFO 01-16 07:03:51 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 01-16 07:04:23 model_runner.py:1523] Graph capturing finished in 32 secs.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import PIL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:07:08.954484Z","iopub.execute_input":"2025-01-16T07:07:08.955115Z","iopub.status.idle":"2025-01-16T07:07:08.958165Z","shell.execute_reply.started":"2025-01-16T07:07:08.955075Z","shell.execute_reply":"2025-01-16T07:07:08.957542Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Refer to the HuggingFace repo for the correct format to use\nprompt = \"USER: <image>\\nWhat is the content of this image?\\nASSISTANT:\"\n\n# Load the image using PIL.Image\nimage = PIL.Image.open(\"/kaggle/input/images2/image2.jpg\")\n\n# Single prompt inference\noutputs = llm.generate({\n    \"prompt\": prompt,\n    \"multi_modal_data\": {\"image\": image},\n})\n\nfor o in outputs:\n    generated_text = o.outputs[0].text\n    print(generated_text)\n\n# Batch inference\nimage_1 = PIL.Image.open('/kaggle/input/images2/image1.jpg')\nimage_2 = PIL.Image.open('/kaggle/input/images2/image2.jpg')\noutputs = llm.generate(\n    [\n        {\n            \"prompt\": \"USER: <image>\\nWhat is the content of this image?\\nASSISTANT:\",\n            \"multi_modal_data\": {\"image\": image_1},\n        },\n        {\n            \"prompt\": \"USER: <image>\\nWhat's the color of this image?\\nASSISTANT:\",\n            \"multi_modal_data\": {\"image\": image_2},\n        }\n    ]\n)\n\nfor o in outputs:\n    generated_text = o.outputs[0].text\n    print(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:10:11.234918Z","iopub.execute_input":"2025-01-16T07:10:11.235687Z","iopub.status.idle":"2025-01-16T07:10:13.994921Z","shell.execute_reply.started":"2025-01-16T07:10:11.235634Z","shell.execute_reply":"2025-01-16T07:10:13.994272Z"}},"outputs":[{"name":"stderr","text":"Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it, est. speed input: 536.24 toks/s, output: 14.40 toks/s]\n","output_type":"stream"},{"name":"stdout","text":" The image features a close-up view of a black bear walking across a grass\n","output_type":"stream"},{"name":"stderr","text":"Processed prompts: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s, est. speed input: 945.26 toks/s, output: 19.81 toks/s]","output_type":"stream"},{"name":"stdout","text":" The image shows an arrangement of electronic and office equipment on a slightly cluttered\n The image is in black and white.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"tokenizer = llm.get_tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:41:57.310870Z","iopub.execute_input":"2025-01-07T02:41:57.311626Z","iopub.status.idle":"2025-01-07T02:41:57.314797Z","shell.execute_reply.started":"2025-01-07T02:41:57.311592Z","shell.execute_reply":"2025-01-07T02:41:57.314029Z"}},"outputs":[],"execution_count":null}]}